So a friend of mine was riding
in a taxi to the airport the other day,
and on the way, she was chatting
with the taxi driver,
and he said to her, with total sincerity,
"I can tell you are a really good person."
And when she told me this story later,
she said she couldn't believe
how good it made her feel,
that it meant a lot to her.
Now that may seem
like a strong reaction from my friend
to the words of a total stranger,
but she's not alone.

I'm a social scientist.
I study the psychology of good people,
and research in my field says
many of us care deeply
about feeling like a good person
and being seen as a good person.
Now, your definition of "good person"
and your definition of "good person"
and maybe the taxi driver's
definition of "good person" —
we may not all have the same definition,
but within whatever our definition is,
that moral identity
is important to many of us.

Now, if somebody challenges it,
like they question us for a joke we tell,
or maybe we say
our workforce is homogenous,
or a slippery business expense,
we go into red-zone defensiveness
a lot of the time.
I mean, sometimes we call out
all the ways in which we help
people from marginalized groups,
or we donate to charity,
or the hours we volunteer to nonprofits.
We work to protect
that good person identity.
It's important to many of us.

But what if I told you this?
What if I told you that our attachment
to being good people
is getting in the way
of us being better people?
What if I told you that our definition
of "good person" is so narrow,
it's scientifically impossible to meet?
And what if I told you
the path to being better people
just begins with letting go
of being a good person?

Now, let me tell you a little bit
about the research
about how the human mind works
to explain.
The brain relies on shortcuts
to do a lot of its work.
That means a lot of the time,
your mental processes are taking place
outside of your awareness,
like in low-battery, low-power mode
in the back of your mind.
That's, in fact, the premise
of bounded rationality.
Bounded rationality is
the Nobel Prize-winning idea
that the human mind
has limited storage resources,
limited processing power,
and as a result, it relies on shortcuts
to do a lot of its work.
So for example,
some scientists estimate
that in any given moment ...
Better, better click, right? There we go.

(Laughter)

At any given moment,
11 million pieces of information
are coming into your mind.
Eleven million.
And only 40 of them
are being processed consciously.
So 11 million, 40.

I mean, has this ever happened to you?
Have you ever had
a really busy day at work,
and you drive home,
and when you get in the door,
you realize you don't
even remember the drive home,
like whether you had
green lights or red lights.
You don't even remember.
You were on autopilot.
Or have you ever opened the fridge,
looked for the butter,
swore there is no butter,
and then realized the butter
was right in front of you the whole time?
These are the kinds of "whoops" moments
that make us giggle,
and this is what happens in a brain
that can handle 11 million
pieces of information coming in
with only 40 being processed consciously.
That's the bounded part
of bounded rationality.

This work on bounded rationality
is what's inspired work I've done
with my collaborators
Max Bazerman and Mahzarin Banaji,
on what we call bounded ethicality.
So it's the same premise
as bounded rationality,
that we have a human mind
that is bounded in some sort of way
and relying on shortcuts,
and that those shortcuts
can sometimes lead us astray.
With bounded rationality,
perhaps it affects the cereal
we buy in the grocery store,
or the product we launch in the boardroom.
With bounded ethicality, the human mind,
the same human mind,
is making decisions,
and here, it's about who to hire next,
or what joke to tell
or that slippery business decision.

So let me give you an example
of bounded ethicality at work.
Unconscious bias is one place
where we see the effects
of bounded ethicality.
So unconscious bias refers
to associations we have in our mind,
the shortcuts your brain is using
to organize information,
very likely outside of your awareness,
not necessarily lining up
with your conscious beliefs.
Researchers Nosek, Banaji and Greenwald
have looked at data
from millions of people,
and what they've found is, for example,
most white Americans
can more quickly and easily
associate white people and good things
than black people and good things,
and most men and women
can more quickly and easily associate
men and science than women and science.
And these associations
don't necessarily line up
with what people consciously think.
They may have
very egalitarian views, in fact.
So sometimes, that 11 million
and that 40 just don't line up.

And here's another example:
conflicts of interest.
So we tend to underestimate
how much a small gift —
imagine a ballpoint pen or dinner —
how much that small gift
can affect our decision making.
We don't realize that our mind
is unconsciously lining up evidence
to support the point of view
of the gift-giver,
no matter how hard we're consciously
trying to be objective and professional.
We also see bounded ethicality —
despite our attachment
to being good people,
we still make mistakes,
and we make mistakes
that sometimes hurt other people,
that sometimes promote injustice,
despite our best attempts,
and we explain away our mistakes
rather than learning from them.
Like, for example,
when I got an email
from a female student in my class
saying that a reading I had assigned,
a reading I had been assigning for years,
was sexist.
Or when I confused
two students in my class
of the same race —
look nothing alike —
when I confused them for each other
more than once, in front of everybody.

These kinds of mistakes send us, send me,
into red-zone defensiveness.
They leave us fighting
for that good person identity.
But the latest work that I've been doing
on bounded ethicality with Mary Kern
says that we're not
only prone to mistakes —
that tendency towards mistakes depends
on how close we are to that red zone.
So most of the time, nobody's challenging
our good person identity,
and so we're not thinking too much
about the ethical implications
of our decisions,
and our model shows
that we're then spiraling
towards less and less
ethical behavior most of the time.

On the other hand, somebody
might challenge our identity,
or, upon reflection,
we may be challenging it ourselves.
So the ethical implications
of our decisions become really salient,
and in those cases, we spiral towards
more and more good person behavior,
or, to be more precise,
towards more and more behavior
that makes us feel like a good person,
which isn't always the same, of course.
The idea with bounded ethicality
is that we are perhaps overestimating
the importance our inner compass
is playing in our ethical decisions.
We perhaps are overestimating
how much our self-interest
is driving our decisions,
and perhaps we don't realize
how much our self-view as a good person
is affecting our behavior,
that in fact, we're working so hard
to protect that good person identity,
to keep out of that red zone,
that we're not actually giving ourselves
space to learn from our mistakes
and actually be better people.

It's perhaps because
we expect it to be easy.
We have this definition
of good person that's either-or.
Either you are a good person
or you're not.
Either you have integrity or you don't.
Either you are a racist or a sexist
or a homophobe or you're not.
And in this either-or definition,
there's no room to grow.
And by the way,
this is not what we do
in most parts of our lives.
Life, if you needed to learn accounting,
you would take an accounting class,
or if you become a parent,
we pick up a book and we read about it.
We talk to experts,
we learn from our mistakes,
we update our knowledge,
we just keep getting better.
But when it comes to being a good person,
we think it's something
we're just supposed to know,
we're just supposed to do,
without the benefit of effort or growth.

So what I've been thinking about
is what if we were to just forget
about being good people,
just let it go,
and instead, set a higher standard,
a higher standard
of being a good-ish person?
A good-ish person
absolutely still makes mistakes.
As a good-ish person,
I'm making them all the time.
But as a good-ish person,
I'm trying to learn from them, own them.
I expect them and I go after them.
I understand there are costs
to these mistakes.
When it comes to issues like ethics
and bias and diversity and inclusion,
there are real costs to real people,
and I accept that.
As a good-ish person, in fact,
I become better
at noticing my own mistakes.
I don't wait for people to point them out.
I practice finding them,
and as a result ...
Sure, sometimes it can be embarrassing,
it can be uncomfortable.
We put ourselves
in a vulnerable place, sometimes.
But through all that vulnerability,
just like in everything else
we've tried to ever get better at,
we see progress.
We see growth.
We allow ourselves to get better.

Why wouldn't we give ourselves that?
In every other part of our lives,
we give ourselves room to grow —
except in this one, where it matters most.

Thank you.

(Applause)