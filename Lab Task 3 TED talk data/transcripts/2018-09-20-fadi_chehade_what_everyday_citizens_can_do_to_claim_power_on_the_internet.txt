Bryn Freedman: So you said
that in the 20th century,
global power was in the hands
of government.
At the beginning of this digital century,
it really moved to corporations
and that in the future,
it would move to individuals.
And I've interviewed a lot of people,
and they say you're wrong,
and they are betting on the companies.
So why are you right,
and why are individuals going to win out?

Fadi Chehadé: Because companies
cater to individuals,
and we as the citizenry
need to start understanding
that we have a big role
in shaping how the world
will be governed, moving forward.
Yes, indeed, the tug of war right now
is between governments,
who lost much of their power to companies
because the internet is not built
around the nation-state system
around which governments have power.
The internet is transnational.
It's not international,
and it's not national,
and therefore the companies
became very powerful.
They shape our economy.
They shape our society.
Governments don't know what to do.
Right now, they're reacting.
And I fear that if we do not,
as the citizenry —
which are, in my opinion,
the most important leg of that stool —
don't take our role,
then you are right.
The detractors, or the people telling you
that businesses will prevail, are right.
It will happen.

BF: So are you saying that individuals
will force businesses
or business will be forced
to be responsive,
or is there a fear that they won't be?

FC: I think they will be.
Look at two weeks ago,
a small company called Skip
winning over Uber and Lyft and everyone
to actually get the license
for the San Francisco scooter business.
And if you read why did Skip win,
because Skip listened
to the people of San Francisco,
who were tired of scooters
being thrown everywhere,
and actually went to the city and said,
"We will deploy the service,
but we will respond
to the people's requirements
that we organize ourselves
around a set of rules."
They self-governed their behavior,
and they won the contract
over some very powerful companies.

BF: So speaking of guidelines
and self-governance,
you've spent an entire lifetime
creating guidelines and norms
for the internet.
Do you think those days are over?
Who is going to guide,
who is going to control,
and who is going to create those norms?

FC: The rules that govern
the technology layers of the internet
are now well put in place,
and I was very busy for a few years
setting those rules
around the part of the internet
that makes the internet one network.
The domain-name system, the IP numbers,
all of that is in place.
However, as we get now
into the upper layers of the internet,
the issues that affect
me and you every day —
privacy, security, etc. —
the system to create norms for those
unfortunately is not in place.
So we do have an issue.
We have a system
of cooperation and governance
that really needs to be created right now
so that companies, governments
and the citizenry can agree
how this new digital world
is going to advance.

BF: So what gives
a digital company any incentive?
Let's say — Facebook comes to mind —
they would say they have
their users' best interests at heart,
but I think a lot of people
would disagree with that.

FC: It's been very difficult to watch
how tech companies have reacted
to the citizenry's response
to their technologies.
And some of them, two or three years ago,
basically dismissed it.
The word that I heard in many board rooms
is, "We're just a technology platform.
It's not my issue
if my technology platform
causes families
to go kill their girls in Pakistan.
It's not my issue. It's their problem.
I just have a technology platform."
Now, I think we are now entering a stage
where companies are starting to realize
this is no longer sustainable,
and they're starting to see the pushback
that's coming
from people, users, citizens,
but also governments
that are starting to say,
"This cannot be."

So I think there is a maturity
that is starting to set,
especially in that Silicon Valley area,
where people are beginning to say,
"We have a role."
So when I speak to these leaders, I say,
"Look, you could be the CEO,
a very successful CEO of a company,
but you could also be a steward."
And that's the key word.
"You could be a steward
of the power you have
to shape the lives and the economies
of billions of people.
Which one do you want to be?"
And the answer is,
it's not one or the other.
This is what we are missing right now.
So when an adult like Brad Smith,
the president of Microsoft,
said a few months ago,
"We need a new set of Geneva Conventions
to manage the security
of the digital space,"
many of the senior leaders
in Silicon Valley
actually spoke against his words.
"What do you mean, Geneva Convention?
We don't need any Geneva Conventions.
We self-regulate."
But that mood is changing,
and I'm starting to see many leaders say,
"Help us out."
But here lies the conundrum.
Who is going to help those leaders
do the right thing?

BF: So who is going to help them?
Because I'd love
to interview you for an hour,
but give me your biggest fear
and your best hope
for how this is going to work out.

FC: My biggest hope
is that we will become each stewards
of this new digital world.
That's my biggest hope,
because I do think, often,
we want to put the blame on others.
"Oh, it's these CEOs.
They're behaving this way."
"These governments are not doing enough."
But how about us?
How is each of us actually taking
the responsibility to be a steward
of the digital space we live in?
And one of the things I've been pushing
on university presidents
is we need every engineering and science
and computer science student
who is about to write
the next line of code
or design the next IoT device
to actually have in them
a sense of responsibility and stewardship
towards what they're building.
So I suggested we create a new oath,
like the Hippocratic Oath,
so that every student
entering an engineering program
takes a technocratic oath or a wisdom oath
or some oath of commitment
to the rest of us.
That's my best hope, that we all rise.
Because governments and businesses
will fight over this power game,
but where are we?
And unless we play into that power table,
I think we'll end up in a bad place.

My biggest fear?
My biggest fear,
to be very tactical today,
what is keeping me up at night
is the current war between
the West, the liberal world,
and China,
in the area of artificial intelligence.
There is a real war going on,
and for those of us who have lived
through the nuclear nonproliferation age
and saw how people agreed
to take some very dangerous
things off the table,
well, the Carnegie Endowment
just finished a study.
They talked to every country
that made nuclear weapons
and asked them,
"Which digital 'weapon'
would you take off the table
against somebody else's
schools or hospitals?"
And the answer —
from every nuclear power —
to this question was,
nothing.
That's what I'm worried about ...
The weaponization of the digital space,
and the race to get there.

BF: Well, it sounds like
you've got a lot of work to do,
and so do the rest of us.
Fadi, thank you so much.
I really appreciate it.

FC: Thank you.

(Applause)