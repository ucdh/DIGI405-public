This is a graph
that represents the economic history
of human civilization.

[World GDP per capita
over the last 200,000 years]

There's not much going on, is there.
For the vast majority of human history,
pretty much everyone lived
on the equivalent of one dollar per day,
and not much changed.
But then, something
extraordinary happened:
the Scientific and Industrial Revolutions.
And the basically flat graph you just saw
transforms into this.
What this graph means is that,
in terms of power to change the world,
we live in an unprecedented time
in human history,
and I believe our ethical understanding
hasn't yet caught up with this fact.
The Scientific and Industrial Revolutions
transformed both
our understanding of the world
and our ability to alter it.
What we need is an ethical revolution
so that we can work out
how do we use this tremendous
bounty of resources
to improve the world.

For the last 10 years,
my colleagues and I have developed
a philosophy and research program
that we call effective altruism.
It tries to respond
to these radical changes in our world,
uses evidence and careful reasoning
to try to answer this question:
How can we do the most good?
Now, there are many issues
you've got to address
if you want to tackle this problem:
whether to do good through your charity
or your career
or your political engagement,
what programs to focus on,
who to work with.
But what I want to talk about
is what I think is the most
fundamental problem.
Of all the many problems
that the world faces,
which should we be focused
on trying to solve first?
Now, I'm going to give you a framework
for thinking about this question,
and the framework is very simple.
A problem's higher priority,
the bigger, the more easily solvable
and the more neglected it is.
Bigger is better,
because we've got more to gain
if we do solve the problem.
More easily solvable is better
because I can solve the problem
with less time or money.
And most subtly,
more neglected is better,
because of diminishing returns.
The more resources that have already been
invested into solving a problem,
the harder it will be
to make additional progress.
Now, the key thing that I want
to leave with you is this framework,
so that you can think for yourself
what are the highest global priorities.
But I and others
in the effective altruism community
have converged on three moral issues
that we believe are unusually important,
score unusually well in this framework.

First is global health.
This is supersolvable.
We have an amazing track record
in global health.
Rates of death from measles,
malaria, diarrheal disease
are down by over 70 percent.
And in 1980, we eradicated smallpox.
I estimate we thereby saved
over 60 million lives.
That's more lives saved
than if we'd achieved world peace
in that same time period.
On our current best estimates,
we can save a life by distributing
long-lasting insecticide-treated bed nets
for just a few thousand dollars.
This is an amazing opportunity.

The second big priority
is factory farming.
This is superneglected.
There are 50 billion land animals
used every year for food,
and the vast majority of them
are factory farmed,
living in conditions
of horrific suffering.
They're probably among
the worst-off creatures on this planet,
and in many cases, we could
significantly improve their lives
for just pennies per animal.
Yet this is hugely neglected.
There are 3,000 times
more animals in factory farms
than there are stray pets,
but yet, factory farming gets one fiftieth
of the philanthropic funding.
That means additional
resources in this area
could have a truly transformative impact.

Now the third area is the one
that I want to focus on the most,
and that's the category
of existential risks:
events like a nuclear war
or a global pandemic
that could permanently derail civilization
or even lead to the extinction
of the human race.
Let me explain why I think
this is such a big priority
in terms of this framework.

First, size.
How bad would it be if there were
a truly existential catastrophe?
Well, it would involve the deaths
of all seven billion people on this planet
and that means you
and everyone you know and love.
That's just a tragedy
of unimaginable size.
But then, what's more,
it would also mean the curtailment
of humanity's future potential,
and I believe that humanity's
potential is vast.
The human race has been around
for about 200,000 years,
and if she lives as long
as a typical mammalian species,
she would last
for about two million years.
If the human race
were a single individual,
she would be just 10 years old today.
And what's more, the human race
isn't a typical mammalian species.
There's no reason why, if we're careful,
we should die off
after only two million years.
The earth will remain habitable
for 500 million years to come.
And if someday, we took to the stars,
the civilization could continue
for billions more.

So I think the future
is going to be really big,
but is it going to be good?
Is the human race
even really worth preserving?
Well, we hear all the time about
how things have been getting worse,
but I think that when
we take the long run,
things have been getting radically better.
Here, for example,
is life expectancy over time.
Here's the proportion of people
not living in extreme poverty.
Here's the number of countries over time
that have decriminalized homosexuality.
Here's the number of countries over time
that have become democratic.
Then, when we look to the future,
there could be so much more to gain again.
We'll be so much richer,
we can solve so many problems
that are intractable today.

So if this is kind of a graph
of how humanity has progressed
in terms of total human
flourishing over time,
well, this is what we would expect
future progress to look like.
It's vast.

Here, for example,
is where we would expect no one
to live in extreme poverty.
Here is where we would expect
everyone to be better off
than the richest person alive today.
Perhaps here is where we would discover
the fundamental natural laws
that govern our world.
Perhaps here is where we discover
an entirely new form of art,
a form of music we currently lack
the ears to hear.
And this is just
the next few thousand years.
Once we think past that,
well, we can't even imagine the heights
that human accomplishment might reach.

So the future could be very big
and it could be very good,
but are there ways
we could lose this value?
And sadly, I think there are.
The last two centuries brought
tremendous technological progress,
but they also brought
the global risks of nuclear war
and the possibility
of extreme climate change.
When we look to the coming centuries,
we should expect to see
the same pattern again.
And we can see some radically
powerful technologies on the horizon.
Synthetic biology might give us
the power to create viruses
of unprecedented
contagiousness and lethality.
Geoengineering might give us the power
to dramatically alter the earth's climate.
Artificial intelligence might give us
the power to create intelligent agents
with abilities greater than our own.
Now, I'm not saying that any
of these risks are particularly likely,
but when there's so much at stake,
even small probabilities
matter a great deal.
Imagine if you're getting on a plane
and you're kind of nervous,
and the pilot reassures you by saying,
"There's only a one-in-a-thousand
chance of crashing. Don't worry."
Would you feel reassured?
For these reasons, I think that preserving
the future of humanity
is among the most important problems
that we currently face.

But let's keep using this framework.
Is this problem neglected?
And I think the answer is yes,
and that's because problems
that affect future generations
are often hugely neglected.
Why?
Because future people
don't participate in markets today.
They don't have a vote.
It's not like there's a lobby
representing the interests
of those born in 2300 AD.
They don't get to influence
the decisions we make today.
They're voiceless.
And that means we still spend
a paltry amount on these issues:
nuclear nonproliferation,
geoengineering, biorisk,
artificial intelligence safety.
All of these receive
only a few tens of millions of dollars
of philanthropic funding every year.
That's tiny compared
to the 390 billion dollars
that's spent on US philanthropy in total.

The final aspect of our framework then:
Is this solvable?
I believe it is.
You can contribute with your money,
your career or your political engagement.
With your money,
you can support organizations
that focus on these risks,
like the Nuclear Threat Initiative,
which campaigns to take nuclear weapons
off hair-trigger alert,
or the Blue Ribbon Panel, which
develops policy to minimize the damage
from natural and man-made pandemics,
or the Center for Human-Compatible AI,
which does technical research
to ensure that AI systems
are safe and reliable.
With your political engagement,
you can vote for candidates
that care about these risks,
and you can support
greater international cooperation.
And then with your career,
there is so much that you can do.
Of course, we need scientists
and policymakers and organization leaders,
but just as importantly,
we also need accountants
and managers and assistants
to work in these organizations
that are tackling these problems.

Now, the research program
of effective altruism
is still in its infancy,
and there's still a huge amount
that we don't know.
But even with what we've learned so far,
we can see that by thinking carefully
and by focusing on those problems
that are big, solvable and neglected,
we can make a truly tremendous
difference to the world
for thousands of years to come.

Thank you.

(Applause)